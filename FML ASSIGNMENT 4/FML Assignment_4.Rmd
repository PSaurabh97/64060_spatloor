---
title: "FML Clustering Assignment 4"
author: "Saurabh Patloori"
date: "2023-11-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(class)
library(caret)
library(e1071)
library(tidyverse)
library(ISLR)
library(factoextra)
library(dbscan)
library(fpc)
```
Import the data which was in CSV format
```{r}
pharma.data <- read.csv("C:/Users/patlo/OneDrive/Desktop/Pharmaceuticals.csv")
dim(pharma.data)
t(t(names(pharma.data)))# The 't' function creates a transpose of the dataframe
```
Dropping the columns that were not required for clustering
```{r}
pharma.data <- pharma.data[ ,-c(1,2,12,13,14)]# 1 and 5 are the indexes for columns ID and ZIP
dim(pharma.data)
summary(pharma.data)
t(t(names(pharma.data)))
```
#kmeans
```{r}
pharma.data1 <- scale(pharma.data)
head(pharma.data1)
distance <- get_dist(pharma.data1)
fviz_dist(distance)
```
Consider k=3
```{r}
set.seed(159)
k <- 3
k3 <- kmeans(pharma.data1, centers = k, nstart=21)
k3$centers
k3$size
k3$cluster
fviz_cluster(k3, pharma.data1)
```
```{r}
fviz_nbclust(pharma.data1, kmeans, method = "wss")
```

# DBSCAN

```{r}
library(dbscan)
d <- read.csv("C:/Users/patlo/OneDrive/Desktop/Pharmaceuticals.csv")
```

```{r}
data1 <- d[ ,-c(1,2,12,13,14)]
data1
```




```{r}
set.seed(12)
db <- dbscan::dbscan(data1, eps = 25, MinPts = 2) #perform clustering

print(db) #print cluster details

```
```{r}
# install_packages("fpc")
library('factoextra')
library('fpc')
df <- data1[, 1:9]

set.seed(123)
db <- fpc::dbscan(data1, eps = 35, MinPts = 1) # DBSCAN using fpc package

print(db) # show clusters' details

```


```{r}
fviz_cluster(db, data1,   stand = FALSE, frame = FALSE, geom = "point") # Alternative way to depict plot

```


#Hierarchical
```{r}
A <- read.csv("C:/Users/patlo/OneDrive/Desktop/Pharmaceuticals.csv")
Sorted.data <- A[ ,-c(1,2,12,13,14)]
```


Compute Euclidean distance
```{r}
# (to compute other distance measures, change the value in method = )
d <- dist(Sorted.data, method = "euclidean")
d.norm <- dist(Sorted.data[,c(4,8)], method = "euclidean")
```

## Table 15.4

```{r}
# normalize input variables
filt.data <- sapply(Sorted.data, scale)

# add row names: utilities
row.names(filt.data) <- row.names(Sorted.data) 

# compute normalized distance based on variables ROE and Rev_Growth
d.norm <- dist(filt.data[,c(4,8)], method = "euclidean")

```

## Figure 15.3
```{r}
# compute normalized distance based on all 8 variables
d.norm <- dist(filt.data, method = "euclidean")

# in hclust() set argument method =  
# to "ward.D", "single", "complete", "average", "median", or "centroid"
hc1 <- hclust(d.norm, method = "single")
plot(hc1, hang = -1, ann = FALSE)
hc2 <- hclust(d.norm, method = "average")
plot(hc2, hang = -1, ann = FALSE)

```


#### Table 15.6

```{r}
memb <- cutree(hc1, k = 3)
memb
memb <- cutree(hc2, k = 3)
memb

```



## Figure 15.4

```{r}
# set labels as cluster membership and utility name
row.names(filt.data) <- paste(memb, ": ", row.names(Sorted.data), sep = "")

# plot heatmap 
# rev() reverses the color mapping to large = dark
heatmap(as.matrix(filt.data), Colv = NA, hclustfun = hclust, 
        col=rev(paste("gray",1:99,sep="")))

```






